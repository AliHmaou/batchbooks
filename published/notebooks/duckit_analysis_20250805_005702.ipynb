{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyse des Propri√©t√©s de l'√âtat : Une Carte Choropleth pour Comprendre la R√©partition D√©partementale\n",
        "\n",
        "\n",
        "L'analyse pr√©sent√©e dans ce notebook se concentre sur les donn√©es relatives aux biens immobiliers appartenant √† l'√âtat fran√ßais, issues du dataset \"Inventaire Immobilier de l'√âtat\" disponible sur le site data.economie.gouv.fr. Ce dataset fournit des informations d√©taill√©es sur la localisation, le type, la fonction et le minist√®re dont d√©pendent ces biens immobiliers. L'objectif principal est de pr√©parer les donn√©es pour cr√©er une carte choropleth qui illustre la r√©partition des propri√©t√©s de l'√âtat au niveau d√©partemental.\n",
        "\n",
        "\n",
        "L'utilisation de ces donn√©es permet non seulement de comprendre la r√©partition g√©ographique des biens immobiliers de l'√âtat mais aussi d'analyser leur diversit√© en termes de type, de fonction et de d√©pendance minist√©rielle. La source des donn√©es, https://data.economie.gouv.fr/api/explore/v2.1/catalog/datasets/inventaire-immobilier-de-letat/exports/csv?use_labels=true, offre un aper√ßu exhaustif de l'inventaire immobilier de l'√âtat, permettant ainsi des analyses approfondies sur la base de crit√®res vari√©s.\n",
        "\n",
        "\n",
        "## M√©thodologie\n",
        "\n",
        "\n",
        "La m√©thodologie adopt√©e pour cette analyse implique plusieurs √©tapes cl√©s. Premi√®rement, les donn√©es sont extraites du dataset \"Inventaire Immobilier de l'√âtat\" et charg√©es dans un dataframe pour traitement. Ensuite, une requ√™te SQL est ex√©cut√©e via DuckDB pour agr√©ger les donn√©es par d√©partement, en calculant le nombre total de propri√©t√©s, le nombre de propri√©t√©s uniques et le nombre de minist√®res diff√©rents repr√©sent√©s dans chaque d√©partement. Les r√©sultats sont ensuite utilis√©s pour cr√©er une carte choropleth √† l'aide de Plotly Express, en superposant les donn√©es agr√©g√©es avec un GeoJSON repr√©sentant les d√©partements fran√ßais.\n",
        "\n",
        "\n",
        "Les donn√©es sont ainsi visualis√©es de mani√®re √† mettre en √©vidence les disparit√©s r√©gionales dans la r√©partition des propri√©t√©s de l'√âtat, facilitant l'identification des d√©partements avec une forte concentration de biens immobiliers et permettant une analyse plus fine de la diversit√© de ces biens en fonction de diff√©rents crit√®res."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation et imports\n",
        "import duckdb as ddb\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü¶Ü Chargement du dataset avec Duckdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
        "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
        "    ddb.execute(\"install spatial\")\n",
        "    ddb.execute(\"load spatial\")\n",
        "    ddb.execute(\"INSTALL h3 FROM community\")\n",
        "    ddb.execute(\"LOAD h3\")\n",
        "    ddb.execute(\"install webbed from community;\")\n",
        "    ddb.execute(\"load webbed\")\n",
        "    ddb.execute(\"set force_download=True\")\n",
        "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
        "    \n",
        "    # D√©tection automatique du type de fichier\n",
        "    if 'csv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'tsv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'txt' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'parquet' in url_dataset: \n",
        "        loader = \"read_parquet\"\n",
        "    elif 'json' in url_dataset: \n",
        "        loader = \"read_json_auto\"\n",
        "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'shp' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'geojson' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'xml' in url_dataset: \n",
        "        loader = \"read_xml\"\n",
        "    elif 'html' in url_dataset: \n",
        "        loader = \"read_html\"\n",
        "    else: \n",
        "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
        "    \n",
        "    if options==\"\": \n",
        "        options = \"\" \n",
        "    if 'csv' in url_dataset and safe_mode==True: \n",
        "        options = \", all_varchar=1\" \n",
        "    if nom_table==\"\": \n",
        "        nom_table = \"loaded_dataset\"\n",
        "    \n",
        "    try:\n",
        "        status = ddb.sql(f\"\"\"\n",
        "            create or replace table {nom_table} as select *\n",
        "            from\n",
        "            {loader}(\"{url_dataset}\" {options})\n",
        "        \"\"\")\n",
        "        return status\n",
        "    except Exception as e:\n",
        "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
        "\n",
        "def run_query(sql):\n",
        "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
        "\n",
        "# Chargement des donn√©es\n",
        "load_file_from_url_lite(\"https://data.economie.gouv.fr/api/explore/v2.1/catalog/datasets/inventaire-immobilier-de-letat/exports/csv?use_labels=true\", safe_mode=True)\n",
        "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Analyse SQL\n",
        "\n",
        "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ex√©cution de la requ√™te\n",
        "df = run_query(\"\"\" SELECT \n",
        "  lpad(\"dept\", 2, '0') AS code_dept,\n",
        "  COUNT(*) AS nb_proprietes,\n",
        "  COUNT(DISTINCT \"id\") AS nb_proprietes_uniques,\n",
        "  COUNT(DISTINCT \"ministere\") AS nb_ministeres\n",
        "FROM \n",
        "  loaded_dataset\n",
        "GROUP BY \n",
        "  \"dept\"\n",
        "ORDER BY \n",
        "  code_dept \"\"\")\n",
        "print(f\"R√©sultats : {len(df)} lignes\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualisation\n",
        "\n",
        "La biblioth√®que principale utilis√©e pour cette datavisualisation est Plotly Express, qui est id√©ale pour cr√©er des cartes interactives et des repr√©sentations graphiques complexes de mani√®re simple et efficace. Le choix d'une carte choropleth est pertinent pour repr√©senter des donn√©es g√©ographiques, telles que le nombre de propri√©t√©s de l'√âtat par d√©partement en France. Cela permet une visualisation claire et intuitive des donn√©es."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import duckdb as ddb\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# R√©cup√©ration du geojson des d√©partements fran√ßais\n",
        "url = \"https://france-geojson.gregoiredavid.fr/repo/departements.geojson\"\n",
        "response = requests.get(url)\n",
        "geojson = response.json()\n",
        "\n",
        "# Mise en forme du code_dept en 2 chiffres\n",
        "df['code_dept'] = df['code_dept'].astype(str).str.zfill(2)\n",
        "\n",
        "# Cr√©ation de la carte choropleth\n",
        "dataviz = px.choropleth_mapbox(\n",
        "    df,\n",
        "    geojson=geojson,\n",
        "    locations='code_dept',\n",
        "    featureidkey=\"properties.code\",\n",
        "    color='nb_proprietes',\n",
        "    color_continuous_scale=\"Blues\",\n",
        "    range_color=[df['nb_proprietes'].min(), df['nb_proprietes'].max()],\n",
        "    mapbox_style=\"carto-positron\",\n",
        "    zoom=4.5,\n",
        "    center={\"lat\": 46.5, \"lon\": 2.5},\n",
        "    opacity=0.7,\n",
        "    labels={'nb_proprietes': \"Nombre de propri√©t√©s\"},\n",
        "    hover_data={\n",
        "        'code_dept': True,\n",
        "        'nb_proprietes': True,\n",
        "        'nb_proprietes_uniques': True,\n",
        "        'nb_ministeres': True\n",
        "    }\n",
        ")\n",
        "\n",
        "# Mise en page finale\n",
        "dataviz.update_layout(\n",
        "    margin=dict(l=0, r=0, t=50, b=0),\n",
        "    title={\n",
        "        'text': \"Carte des propri√©t√©s de l'√âtat par d√©partement\",\n",
        "        'x': 0.5,\n",
        "        'xanchor': 'center',\n",
        "        'font': dict(size=16, family=\"Segoe UI\")\n",
        "    },\n",
        "    coloraxis_colorbar_title_text=\"Nb propri√©t√©s\",\n",
        "    coloraxis_colorbar_len=0.8\n",
        ")\n",
        "dataviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}