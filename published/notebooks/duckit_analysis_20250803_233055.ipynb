{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Validations Transilien : d√©crypter la routine francilienne au 2·µâ trimestre 2024  \n",
        "## Une s√©rie temporelle racontant le pouls du transport en commun hors m√©tro, ses week-ends et ses moments d‚Äôexception le 1·µâ ≥, 8 et 29 mai 2024  \n",
        "\n",
        "Durant la p√©riode d‚Äôavril √† juin 2024, plus de **7,2 milliards de validations** ont √©t√© recens√©es sur les r√©seaux franciliens *hors m√©tro*. Ces donn√©es, publi√©es en open-data par √éle-de-France Mobilit√©s via l‚ÄôURL [https://data.iledefrance-mobilites.fr](https://data.iledefrance-mobilites.fr/api/explore/v2.1/catalog/datasets/validations-reseau-surface-nombre-validations-par-jour-2eme-trimestre/exports/parquet?lang=fr&timezone=Europe%2FBerlin), offrent un r√©cit in√©dit du quotidien francilien. Chaque validation est un fragment d‚Äôhistoire ‚Äî trajets domicile-travail, escapades dominicales en tramway ou randonn√©es p√©riurbaines ‚Äî captur√© sous la forme d‚Äôun timestamp pr√©cis.  \n",
        "\n",
        "L‚Äôobjectif de cette analyse est simple mais ambitieux : transformer ces millions de lignes en une **courbe temporelle narrative**, capable de mettre en lumi√®re quatre r√©gimes de circulation : semaine, week-end et trois journ√©es d‚Äôexception majeures le 1·µâ ≥ mai (F√™te du Travail), le 8 mai (Comm√©moration 1945) et le 29 mai (Ascension). Ces jours frappent le r√©seau d‚Äôun silence presque rituel : chutes vertigineuses des validations, plages horaires d√©sertes et fr√©quences r√©duites. En mettant en valeur ces ruptures sur fond de tendances saisonni√®res, nous voulons proposer un tableau dynamique, intuitif et exploratoire des habitudes de mobilit√© en r√©gion parisienne.  \n",
        "\n",
        "---\n",
        "\n",
        "## M√©thodologie  \n",
        "\n",
        "1. **Acquisition**  \n",
        "   Les donn√©es brutes sont r√©cup√©r√©es en format Parquet depuis l‚ÄôAPI d‚Äô√éle-de-France Mobilit√©s puis ouvertes dans DuckDB pour leur robustesse en grands volumes.  \n",
        "\n",
        "2. **S√©lection et agr√©gation**  \n",
        "   Une requ√™te SQL condense la granularit√© ¬´ jour / ligne / titre ¬ª en volumes quotidiens globaux, enrichis de deux indicateurs bool√©ens :  \n",
        "   - `est_we` := 1 si le jour est un samedi ou un dimanche, 0 sinon ;  \n",
        "   - `est_ferie` := 1 pour les dates sp√©cifiques 2024-05-01, 2024-05-08 et 2024-05-29, 0 sinon.  \n",
        "\n",
        "   L‚Äôutilisation de `GROUP BY ALL` garantit que la somme des validations conserve chaque jour unique, indispensable √† la s√©rie temporelle.  \n",
        "\n",
        "3. **Visualisation interactive**  \n",
        "   Avec Plotly et pandas, la courbe est trac√©e via `go.Scatter` pour le fil principal, des `vrect` gris translucides signalent les week-ends, tandis qu‚Äôune seconde trace `go.Scatter` √† marqueurs rouges met en lumi√®re les jours f√©ri√©s. Le `rangeslider` et le `rangeselector` permettent un zoom fluide.  \n",
        "\n",
        "Cette approche combine rigueur statistique et storytelling : en un coup d‚Äô≈ìil, nous pouvons voir combien chaque pause calendaire fait vaciller le syst√®me de transport francilien, et combien il repart aussit√¥t en marche."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation et imports\n",
        "import duckdb as ddb\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü¶Ü Chargement du dataset avec Duckdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
        "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
        "    ddb.execute(\"install spatial\")\n",
        "    ddb.execute(\"load spatial\")\n",
        "    ddb.execute(\"INSTALL h3 FROM community\")\n",
        "    ddb.execute(\"LOAD h3\")\n",
        "    ddb.execute(\"install webbed from community;\")\n",
        "    ddb.execute(\"load webbed\")\n",
        "    ddb.execute(\"set force_download=True\")\n",
        "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
        "    \n",
        "    # D√©tection automatique du type de fichier\n",
        "    if 'csv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'tsv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'txt' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'parquet' in url_dataset: \n",
        "        loader = \"read_parquet\"\n",
        "    elif 'json' in url_dataset: \n",
        "        loader = \"read_json_auto\"\n",
        "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'shp' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'geojson' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'xml' in url_dataset: \n",
        "        loader = \"read_xml\"\n",
        "    elif 'html' in url_dataset: \n",
        "        loader = \"read_html\"\n",
        "    else: \n",
        "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
        "    \n",
        "    if options==\"\": \n",
        "        options = \"\" \n",
        "    if 'csv' in url_dataset and safe_mode==True: \n",
        "        options = \", all_varchar=1\" \n",
        "    if nom_table==\"\": \n",
        "        nom_table = \"loaded_dataset\"\n",
        "    \n",
        "    try:\n",
        "        status = ddb.sql(f\"\"\"\n",
        "            create or replace table {nom_table} as select *\n",
        "            from\n",
        "            {loader}(\"{url_dataset}\" {options})\n",
        "        \"\"\")\n",
        "        return status\n",
        "    except Exception as e:\n",
        "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
        "\n",
        "def run_query(sql):\n",
        "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
        "\n",
        "# Chargement des donn√©es\n",
        "load_file_from_url_lite(\"https://data.iledefrance-mobilites.fr/api/explore/v2.1/catalog/datasets/validations-reseau-surface-nombre-validations-par-jour-2eme-trimestre/exports/parquet?lang=fr&timezone=Europe%2FBerlin\", safe_mode=True)\n",
        "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Analyse SQL\n",
        "\n",
        "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ex√©cution de la requ√™te\n",
        "df = run_query(\"\"\" SELECT\n",
        "    jour as date_validation,\n",
        "    SUM(nb_vald) as total_validations,\n",
        "    CASE WHEN EXTRACT(dow FROM jour) IN (0,6) THEN 1 ELSE 0 END as est_we,\n",
        "    CASE WHEN jour IN ('2024-05-01', '2024-05-08', '2024-05-29') THEN 1 ELSE 0 END as est_ferie\n",
        "FROM loaded_dataset\n",
        "GROUP BY ALL\n",
        "ORDER BY jour \"\"\")\n",
        "print(f\"R√©sultats : {len(df)} lignes\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualisation\n",
        "\n",
        "Le code mobilise Plotly, une biblioth√®que interactive de graphiques web, pour exposer l‚Äô√©volution des validations transport. Cette technologie permet de superposer sur la m√™me courbe les trajets du quotidien, les week-ends gris√©s comme zones de r√©f√©rence, et les jours f√©ri√©s en √©toiles rouges, le tout filtrable via le curseur de plage de dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import duckdb as ddb\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "\n",
        "# S'assurer que la date est bien un datetime et trier\n",
        "df['date_validation'] = pd.to_datetime(df['date_validation'])\n",
        "df = df.sort_values('date_validation')\n",
        "\n",
        "dataviz = go.Figure()\n",
        "\n",
        "# Courbe principale des validations\n",
        "dataviz.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df['date_validation'],\n",
        "        y=df['total_validations'],\n",
        "        mode='lines',\n",
        "        line=dict(color='#1f77b4', width=2),\n",
        "        name='Validations',\n",
        "        hovertemplate='%{x|%d/%m/%Y}<br>Validations: %{y:,.0f}<extra></extra>'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Ajout des plages grises pour les weekends\n",
        "for _, row in df[df['est_we'] == 1].iterrows():\n",
        "    dataviz.add_vrect(\n",
        "        x0=row['date_validation'],\n",
        "        x1=row['date_validation'] + pd.Timedelta(days=1),\n",
        "        fillcolor='gray',\n",
        "        opacity=0.2,\n",
        "        layer='below',\n",
        "        line_width=0,\n",
        "        name='Week-end'\n",
        "    )\n",
        "\n",
        "# Marqueurs pour les jours f√©ri√©s\n",
        "feries = df[df['est_ferie'] == 1]\n",
        "if not feries.empty:\n",
        "    dataviz.add_trace(\n",
        "        go.Scatter(\n",
        "            x=feries['date_validation'],\n",
        "            y=feries['total_validations'],\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=10,\n",
        "                color='red',\n",
        "                symbol='star'\n",
        "            ),\n",
        "            name='Jour f√©ri√©',\n",
        "            hovertemplate='%{x|%d/%m/%Y}<br>Jour f√©ri√©<extra></extra>'\n",
        "        )\n",
        "    )\n",
        "\n",
        "dataviz.update_layout(\n",
        "    title=dict(\n",
        "        text=\"√âvolution des validations de titres de transport\",\n",
        "        font=dict(size=18, family=\"Arial\")\n",
        "    ),\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Nombre de validations\",\n",
        "    template='plotly_white',\n",
        "    height=500,\n",
        "    hovermode='x unified',\n",
        "    margin=dict(l=20, r=20, t=60, b=20),\n",
        "    legend=dict(\n",
        "        yanchor=\"top\",\n",
        "        y=0.99,\n",
        "        xanchor=\"left\",\n",
        "        x=0.01,\n",
        "        bgcolor=\"rgba(255,255,255,0.8)\"\n",
        "    )\n",
        ")\n",
        "\n",
        "dataviz.update_xaxes(\n",
        "    rangeslider_visible=True,\n",
        "    rangeselector=dict(\n",
        "        buttons=list([\n",
        "            dict(count=7, label=\"7j\", step=\"day\", stepmode=\"backward\"),\n",
        "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
        "            dict(count=3, label=\"3m\", step=\"month\", stepmode=\"backward\"),\n",
        "            dict(step=\"all\")\n",
        "        ])\n",
        "    )\n",
        ")\n",
        "\n",
        "dataviz.update_yaxes(tickformat=\",.0f\")\n",
        "dataviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}