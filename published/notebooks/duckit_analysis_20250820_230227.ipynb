{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de l'Amplitude Thermique Cumulative en Occitanie : Tendances et Insights\n",
    "\n",
    "\n",
    "L'analyse pr√©sent√©e dans ce notebook se concentre sur l'exploration des donn√©es m√©t√©orologiques quotidiennes de la r√©gion Occitanie, en particulier sur l'amplitude thermique journali√®re et sa somme cumulative annuelle. Les donn√©es utilis√©es proviennent du site data.gouv.fr et sont accessibles via l'URL : https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_34_previous-1950-2023_RR-T-Vent.csv.gz. Ce fichier contient des informations m√©t√©orologiques d√©taill√©es relev√©es dans diff√©rentes stations de la r√©gion, couvrant une p√©riode allant de 1950 √† 2023.\n",
    "\n",
    "\n",
    "L'objectif principal de cette analyse est de calculer la somme cumulative de l'amplitude thermique journali√®re pour chaque ann√©e, en moyennant d'abord sur toutes les stations, et en ne gardant que la valeur de fin de chaque ann√©e. Cette approche permet d'identifier les tendances et les variations dans l'amplitude thermique cumulative sur le long terme, offrant ainsi des insights pr√©cieux pour comprendre les dynamiques climatiques en Occitanie.\n",
    "\n",
    "\n",
    "## M√©thodologie\n",
    "\n",
    "La m√©thodologie adopt√©e pour cette analyse implique plusieurs √©tapes cl√©s. Tout d'abord, les donn√©es sont charg√©es et nettoy√©es pour pr√©parer l'analyse. Ensuite, une requ√™te SQL est ex√©cut√©e via DuckDB pour calculer l'amplitude thermique journali√®re moyenne par jour sur toutes les stations, puis pour d√©terminer la somme cumulative de cette amplitude pour chaque ann√©e. Les r√©sultats sont ensuite filtr√©s pour ne conserver que la derni√®re valeur de chaque ann√©e. Enfin, les donn√©es r√©sultantes sont visualis√©es √† l'aide de Plotly pour mettre en √©vidence les tendances et les points notables dans l'amplitude thermique cumulative.\n",
    "\n",
    "\n",
    "Les r√©sultats de cette analyse sont pr√©sent√©s sous forme de graphiques interactifs, permettant une exploration d√©taill√©e des tendances et des variations dans l'amplitude thermique cumulative en Occitanie sur la p√©riode √©tudi√©e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:00:57.741451Z",
     "iopub.status.busy": "2025-08-21T10:00:57.741451Z",
     "iopub.status.idle": "2025-08-21T10:00:58.467463Z",
     "shell.execute_reply": "2025-08-21T10:00:58.467463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Installation et imports\n",
    "import duckdb as ddb\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶Ü Chargement du dataset avec Duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:00:58.467463Z",
     "iopub.status.busy": "2025-08-21T10:00:58.467463Z",
     "iopub.status.idle": "2025-08-21T10:01:09.451532Z",
     "shell.execute_reply": "2025-08-21T10:01:09.451532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9bfead72cd4023bb220192037d4118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
    "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
    "    ddb.execute(\"install spatial\")\n",
    "    ddb.execute(\"load spatial\")\n",
    "    ddb.execute(\"INSTALL h3 FROM community\")\n",
    "    ddb.execute(\"LOAD h3\")\n",
    "    ddb.execute(\"install webbed from community;\")\n",
    "    ddb.execute(\"load webbed\")\n",
    "    ddb.execute(\"set force_download=True\")\n",
    "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
    "    \n",
    "    # D√©tection automatique du type de fichier\n",
    "    if 'csv' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'tsv' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'txt' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'parquet' in url_dataset: \n",
    "        loader = \"read_parquet\"\n",
    "    elif 'json' in url_dataset: \n",
    "        loader = \"read_json_auto\"\n",
    "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'shp' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'geojson' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'xml' in url_dataset: \n",
    "        loader = \"read_xml\"\n",
    "    elif 'html' in url_dataset: \n",
    "        loader = \"read_html\"\n",
    "    else: \n",
    "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
    "    \n",
    "    if options==\"\": \n",
    "        options = \"\" \n",
    "    if 'csv' in url_dataset and safe_mode==True: \n",
    "        options = \", all_varchar=1\" \n",
    "    if nom_table==\"\": \n",
    "        nom_table = \"loaded_dataset\"\n",
    "    \n",
    "    try:\n",
    "        status = ddb.sql(f\"\"\"\n",
    "            create or replace table {nom_table} as select *\n",
    "            from\n",
    "            {loader}(\"{url_dataset}\" {options})\n",
    "        \"\"\")\n",
    "        return status\n",
    "    except Exception as e:\n",
    "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
    "\n",
    "def run_query(sql):\n",
    "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
    "\n",
    "# Chargement des donn√©es\n",
    "load_file_from_url_lite(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_34_previous-1950-2023_RR-T-Vent.csv.gz\", safe_mode=True)\n",
    "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Analyse SQL\n",
    "\n",
    "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:01:09.451532Z",
     "iopub.status.busy": "2025-08-21T10:01:09.451532Z",
     "iopub.status.idle": "2025-08-21T10:01:09.673702Z",
     "shell.execute_reply": "2025-08-21T10:01:09.673702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©sultats : 74 lignes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>AAAAMMJJ</th>\n",
       "      <th>cumulative_amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>19501231</td>\n",
       "      <td>3777.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951</td>\n",
       "      <td>19511231</td>\n",
       "      <td>3513.591667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952</td>\n",
       "      <td>19521231</td>\n",
       "      <td>3597.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953</td>\n",
       "      <td>19531231</td>\n",
       "      <td>3557.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954</td>\n",
       "      <td>19541231</td>\n",
       "      <td>3709.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  AAAAMMJJ  cumulative_amplitude\n",
       "0  1950  19501231           3777.683333\n",
       "1  1951  19511231           3513.591667\n",
       "2  1952  19521231           3597.383333\n",
       "3  1953  19531231           3557.633333\n",
       "4  1954  19541231           3709.083333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex√©cution de la requ√™te\n",
    "df = run_query(\"\"\" WITH \n",
    "-- Calculer l'amplitude thermique journali√®re moyenne par jour sur toutes les stations\n",
    "daily_avg AS (\n",
    "    SELECT \n",
    "        \"AAAAMMJJ\", \n",
    "        AVG(CAST(\"TX\" AS DOUBLE) - CAST(\"TN\" AS DOUBLE)) AS avg_amplitude\n",
    "    FROM \n",
    "        loaded_dataset\n",
    "    GROUP BY \n",
    "        \"AAAAMMJJ\"\n",
    "),\n",
    "-- Extraire l'ann√©e et calculer la somme cumulative de l'amplitude thermique\n",
    "cumulative_sum AS (\n",
    "    SELECT \n",
    "        SUBSTRING(CAST(\"AAAAMMJJ\" AS VARCHAR), 1, 4) AS year,\n",
    "        \"AAAAMMJJ\",\n",
    "        avg_amplitude,\n",
    "        SUM(avg_amplitude) OVER (PARTITION BY SUBSTRING(CAST(\"AAAAMMJJ\" AS VARCHAR), 1, 4) ORDER BY \"AAAAMMJJ\") AS cumulative_amplitude\n",
    "    FROM \n",
    "        daily_avg\n",
    ")\n",
    "-- Ne garder que la derni√®re valeur de chaque ann√©e\n",
    "SELECT \n",
    "    year, \n",
    "    \"AAAAMMJJ\", \n",
    "    cumulative_amplitude\n",
    "FROM \n",
    "    cumulative_sum\n",
    "WHERE \n",
    "    \"AAAAMMJJ\" IN (SELECT MAX(\"AAAAMMJJ\") FROM cumulative_sum GROUP BY year)\n",
    "ORDER BY \n",
    "    year \"\"\")\n",
    "print(f\"R√©sultats : {len(df)} lignes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualisation\n",
    "\n",
    "La biblioth√®que principale utilis√©e est Plotly, qui permet de cr√©er des visualisations interactives et personnalisables. Cette technologie est adapt√©e pour repr√©senter des donn√©es complexes avec plusieurs couches d'information, comme ici o√π l'on affiche des points de donn√©es brutes, une courbe brute et une courbe liss√©e avec des annotations. Plotly offre une grande flexibilit√© pour cr√©er des graphiques attractifs et informatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:01:09.673702Z",
     "iopub.status.busy": "2025-08-21T10:01:09.673702Z",
     "iopub.status.idle": "2025-08-21T10:01:10.563438Z",
     "shell.execute_reply": "2025-08-21T10:01:10.563438Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubplots\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_subplots\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_filter1d\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Nettoyage rapide\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAAAMMJJ\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[:\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb as ddb\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# Nettoyage rapide\n",
    "df['year'] = df['AAAAMMJJ'].astype(str).str[:4].astype(int)\n",
    "\n",
    "# Cr√©ation graphe\n",
    "fig = go.Figure()\n",
    "\n",
    "# 1. Points bruts rouge clair\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['year'], \n",
    "    y=df['cumulative_amplitude'],\n",
    "    mode='markers',\n",
    "    name='Donn√©es brutes (fin d‚Äôann√©e)',\n",
    "    marker=dict(color='#FF9999', size=6, opacity=0.9)\n",
    "))\n",
    "\n",
    "# 2. Ligne brute gris tr√®s clair\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['year'], \n",
    "    y=df['cumulative_amplitude'],\n",
    "    mode='lines',\n",
    "    name='Courbe brute',\n",
    "    line=dict(color='#E5E5E5', width=1)\n",
    "))\n",
    "\n",
    "# 3. Lisse - rolling 5 ans pr√©c√©dents\n",
    "roll = (\n",
    "    pd.Series(df['cumulative_amplitude'])\n",
    "      .rolling(window=5, center=True, min_periods=1)\n",
    "      .mean()\n",
    ").values\n",
    "\n",
    "# Ajout du trace liss√© aire bleue\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df['year'], \n",
    "    y=roll,\n",
    "    fill='tonexty',\n",
    "    mode='lines',\n",
    "    name='Courbe liss√©e 5 ans',\n",
    "    line=dict(color='#007acc', width=2.5),\n",
    "    fillcolor='rgba(0,122,204,0.25)'\n",
    "))\n",
    "\n",
    "# Top 10 annotations avec tooltip personnalis√©\n",
    "top10 = df.nlargest(10, 'cumulative_amplitude')\n",
    "for _, row in top10.iterrows():\n",
    "    fig.add_annotation(\n",
    "        x=row['year'],\n",
    "        y=row['cumulative_amplitude'],\n",
    "        text=str(row['year']),\n",
    "        font=dict(size=9, color='black'),\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=0.7,\n",
    "        arrowwidth=1,\n",
    "        ax=0,\n",
    "        ay=-30,\n",
    "        align='center',\n",
    "        bgcolor='#FFFFFF',\n",
    "        bordercolor='#CCCCCC',\n",
    "        borderwidth=0.5\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=None,\n",
    "    margin=dict(l=20, r=20, t=40, b=60),\n",
    "    xaxis_title='Ann√©e',\n",
    "    yaxis_title='Amplitude thermique cumulative (¬∞C)',\n",
    "    legend=dict(\n",
    "        x=0.01, y=0.99,\n",
    "        bgcolor='rgba(255,255,255,0.85)', bordercolor='LightGray', borderwidth=0.5\n",
    "    ),\n",
    "    template='plotly_white',\n",
    "    height=450,\n",
    "    xaxis=dict(dtick=5, showspikes=False),\n",
    "    yaxis=dict(\n",
    "        showspikes=False,\n",
    "        gridcolor='#F5F5F5'\n",
    "    ),\n",
    "    plot_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "dataviz = fig\n",
    "dataviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:01:10.563438Z",
     "iopub.status.busy": "2025-08-21T10:01:10.563438Z",
     "iopub.status.idle": "2025-08-21T10:01:11.182078Z",
     "shell.execute_reply": "2025-08-21T10:01:11.182078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVERTISSEMENT: Aucune variable 'dataviz' trouv√©e.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Variables inject√©es par le script ---\n",
    "FINAL_OBJECT_VARIABLE_NAME = 'dataviz'\n",
    "OUTPUT_IMAGE_NAME = 'published\\\\notebooks\\\\duckit_analysis_20250820_230227.png'\n",
    "OUTPUT_HTML_NAME = 'published\\\\notebooks\\\\duckit_analysis_20250820_230227.html'\n",
    "\n",
    "# ===================================================================\n",
    "# CELLULE INJECT√âE AUTOMATIQUEMENT (VERSION ROBUSTE)\n",
    "# ===================================================================\n",
    "import sys\n",
    "import os\n",
    "# On importe les modules n√©cessaires pour l'export au cas o√π\n",
    "try:\n",
    "    from bokeh.io import save as bokeh_save\n",
    "except ImportError:\n",
    "    bokeh_save = None\n",
    "\n",
    "try:\n",
    "    # On s'assure que le dossier de sortie existe\n",
    "    output_dir = os.path.dirname(OUTPUT_IMAGE_NAME)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # On utilise globals().get() pour une r√©cup√©ration plus s√ªre\n",
    "    final_object = globals().get(FINAL_OBJECT_VARIABLE_NAME)\n",
    "\n",
    "    if final_object is None:\n",
    "        # On l√®ve une NameError pour √™tre coh√©rent avec le code original\n",
    "        raise NameError(f\"name '{FINAL_OBJECT_VARIABLE_NAME}' is not defined\")\n",
    "\n",
    "    print(f\"INFO: Variable '{FINAL_OBJECT_VARIABLE_NAME}' trouv√©e. Tentative d'exportation...\")\n",
    "\n",
    "    object_type = str(type(final_object))\n",
    "\n",
    "    if 'plotly.graph_objs._figure.Figure' in object_type:\n",
    "        print(f\"--> D√©tect√© : Plotly. Sauvegarde HTML et PNG.\")\n",
    "        # 1. Sauvegarde HTML pour l'interactivit√©\n",
    "        print(f\"--> Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.write_html(OUTPUT_HTML_NAME, include_plotlyjs='cdn')\n",
    "        # 2. Sauvegarde PNG pour l'aper√ßu statique\n",
    "        try:\n",
    "            print(f\"--> Tentative de sauvegarde PNG directe dans : {OUTPUT_IMAGE_NAME}\")\n",
    "            final_object.write_image(OUTPUT_IMAGE_NAME, scale=3, width=1200, height=800)\n",
    "            print(f\"--> Image Plotly sauvegard√©e avec succ√®s.\")\n",
    "        except Exception as e:\n",
    "            print(f\"AVERTISSEMENT: La sauvegarde directe en PNG a √©chou√© (kaleido est-il install√©?).\", file=sys.stderr)\n",
    "            print(f\"   Erreur: {e}\", file=sys.stderr)\n",
    "            print(f\"--> PLAN B: On va utiliser la capture d'√©cran du HTML √† la place.\")\n",
    "            # On cr√©e un fichier marqueur pour que le script de post-traitement prenne le relais\n",
    "            with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "                f.write(\"plotly\")\n",
    "    elif 'folium.folium.Map' in object_type:\n",
    "        print(f\"--> D√©tect√© : Folium. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.save(OUTPUT_HTML_NAME)\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"folium\")\n",
    "    elif 'altair.vegalite' in object_type and hasattr(final_object, 'save'):\n",
    "        print(f\"--> D√©tect√© : Altair. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.save(OUTPUT_HTML_NAME)\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"altair\")\n",
    "    elif 'bokeh.plotting' in object_type and bokeh_save is not None:\n",
    "        print(f\"--> D√©tect√© : Bokeh. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        bokeh_save(final_object, filename=OUTPUT_HTML_NAME, title=\"\")\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"bokeh\")\n",
    "    elif 'matplotlib.figure.Figure' in object_type:\n",
    "        print(f\"--> D√©tect√© : Matplotlib. Sauvegarde dans : {OUTPUT_IMAGE_NAME}\")\n",
    "        final_object.savefig(OUTPUT_IMAGE_NAME, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        print(f\"AVERTISSEMENT: Type non support√© : {object_type}\", file=sys.stderr)\n",
    "except NameError:\n",
    "    print(f\"AVERTISSEMENT: Aucune variable '{FINAL_OBJECT_VARIABLE_NAME}' trouv√©e.\", file=sys.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR lors de l'exportation : {e}\", file=sys.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a9bfead72cd4023bb220192037d4118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f8a2fa74fd34602917a25a312796e08",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2217d3acb83c46b99c85b513bd6d4883",
       "tabbable": null,
       "tooltip": null,
       "value": 100.0
      }
     },
     "1f8a2fa74fd34602917a25a312796e08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "2217d3acb83c46b99c85b513bd6d4883": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
