{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Tendances Climatiques en France : √âvolution des Variables M√©t√©orologiques de 1950 √† 2023\n",
    "\n",
    "L'analyse pr√©sent√©e dans ce notebook se concentre sur l'exploration des donn√©es m√©t√©orologiques quotidiennes collect√©es par M√©t√©o France entre 1950 et 2023. Les donn√©es proviennent du fichier `Q_64_previous-1950-2023_RR-T-Vent.csv.gz`, disponible √† l'adresse https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_64_previous-1950-2023_RR-T-Vent.csv.gz. Ce fichier contient des informations d√©taill√©es sur les conditions m√©t√©orologiques quotidiennes enregistr√©es dans divers postes m√©t√©orologiques en France, notamment les pr√©cipitations, les temp√©ratures minimales et maximales, ainsi que d'autres variables.\n",
    "\n",
    "L'objectif principal de cette analyse est de calculer la somme cumul√©e des moyennes journali√®res de certaines variables m√©t√©orologiques cl√©s (pr√©cipitations, temp√©ratures moyennes, maximales et minimales) pour chaque ann√©e, en se concentrant sur la valeur de fin d'ann√©e pour chaque variable. Cela permettra d'√©tudier l'√©volution de ces variables sur le temps et d'identifier d'√©ventuelles tendances climatiques.\n",
    "\n",
    "\n",
    "## M√©thodologie\n",
    "\n",
    "La m√©thodologie employ√©e dans cette analyse repose sur l'utilisation de DuckDB pour traiter et analyser les donn√©es m√©t√©orologiques. La premi√®re √©tape consiste √† charger les donn√©es et √† calculer les moyennes journali√®res pour les variables d'int√©r√™t. Ensuite, une somme cumul√©e de ces moyennes est calcul√©e pour chaque ann√©e. Les r√©sultats sont finalement filtr√©s pour ne conserver que la valeur de fin d'ann√©e pour chaque variable, permettant ainsi d'√©tudier leur √©volution annuelle. Les donn√©es r√©sultantes sont ensuite visualis√©es √† l'aide de Matplotlib et Seaborn pour mettre en √©vidence les tendances observ√©es.\n",
    "\n",
    "\n",
    " \n",
    "Les d√©tails de la requ√™te SQL utilis√©e pour l'analyse sont cruciaux pour comprendre les √©tapes de traitement. La requ√™te commence par calculer les moyennes journali√®res pour les variables m√©t√©orologiques, puis proc√®de au calcul de la somme cumul√©e de ces moyennes pour chaque ann√©e. Finalement, seules les valeurs de fin d'ann√©e sont conserv√©es pour chaque variable.\n",
    "\n",
    "\n",
    "Une visualisation soign√©e est propos√©e pour illustrer les r√©sultats de l'analyse. Les courbes de tendance pour les cumuls annuels de pr√©cipitations, temp√©ratures moyennes, maximales et minimales sont trac√©es, avec un lissage sur 10 ans pour mettre en √©vidence les tendances √† long terme. Les visualisations sont r√©alis√©es avec soin pour offrir une repr√©sentation claire et informative des donn√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:00:18.479617Z",
     "iopub.status.busy": "2025-08-21T10:00:18.479617Z",
     "iopub.status.idle": "2025-08-21T10:00:19.049732Z",
     "shell.execute_reply": "2025-08-21T10:00:19.049732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Installation et imports\n",
    "import duckdb as ddb\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶Ü Chargement du dataset avec Duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:00:19.049732Z",
     "iopub.status.busy": "2025-08-21T10:00:19.049732Z",
     "iopub.status.idle": "2025-08-21T10:00:28.452009Z",
     "shell.execute_reply": "2025-08-21T10:00:28.452009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5748ebf7fbd74f75b31cbb765b13ab49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
    "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
    "    ddb.execute(\"install spatial\")\n",
    "    ddb.execute(\"load spatial\")\n",
    "    ddb.execute(\"INSTALL h3 FROM community\")\n",
    "    ddb.execute(\"LOAD h3\")\n",
    "    ddb.execute(\"install webbed from community;\")\n",
    "    ddb.execute(\"load webbed\")\n",
    "    ddb.execute(\"set force_download=True\")\n",
    "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
    "    \n",
    "    # D√©tection automatique du type de fichier\n",
    "    if 'csv' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'tsv' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'txt' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'parquet' in url_dataset: \n",
    "        loader = \"read_parquet\"\n",
    "    elif 'json' in url_dataset: \n",
    "        loader = \"read_json_auto\"\n",
    "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'shp' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'geojson' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'xml' in url_dataset: \n",
    "        loader = \"read_xml\"\n",
    "    elif 'html' in url_dataset: \n",
    "        loader = \"read_html\"\n",
    "    else: \n",
    "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
    "    \n",
    "    if options==\"\": \n",
    "        options = \"\" \n",
    "    if 'csv' in url_dataset and safe_mode==True: \n",
    "        options = \", all_varchar=1\" \n",
    "    if nom_table==\"\": \n",
    "        nom_table = \"loaded_dataset\"\n",
    "    \n",
    "    try:\n",
    "        status = ddb.sql(f\"\"\"\n",
    "            create or replace table {nom_table} as select *\n",
    "            from\n",
    "            {loader}(\"{url_dataset}\" {options})\n",
    "        \"\"\")\n",
    "        return status\n",
    "    except Exception as e:\n",
    "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
    "\n",
    "def run_query(sql):\n",
    "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
    "\n",
    "# Chargement des donn√©es\n",
    "load_file_from_url_lite(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_64_previous-1950-2023_RR-T-Vent.csv.gz\", safe_mode=True)\n",
    "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Analyse SQL\n",
    "\n",
    "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:00:28.452009Z",
     "iopub.status.busy": "2025-08-21T10:00:28.452009Z",
     "iopub.status.idle": "2025-08-21T10:00:28.738046Z",
     "shell.execute_reply": "2025-08-21T10:00:28.738046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©sultats : 74 lignes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annee</th>\n",
       "      <th>cum_rr_end_year</th>\n",
       "      <th>cum_tm_end_year</th>\n",
       "      <th>cum_tx_end_year</th>\n",
       "      <th>cum_tn_end_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>1354.693791</td>\n",
       "      <td>4973.35</td>\n",
       "      <td>6319.083333</td>\n",
       "      <td>2722.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951</td>\n",
       "      <td>1537.841796</td>\n",
       "      <td>4766.50</td>\n",
       "      <td>5870.350000</td>\n",
       "      <td>2546.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952</td>\n",
       "      <td>1583.263803</td>\n",
       "      <td>4852.20</td>\n",
       "      <td>6059.233333</td>\n",
       "      <td>2542.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953</td>\n",
       "      <td>915.175000</td>\n",
       "      <td>4638.45</td>\n",
       "      <td>6016.910000</td>\n",
       "      <td>2443.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954</td>\n",
       "      <td>1498.891898</td>\n",
       "      <td>4490.85</td>\n",
       "      <td>5693.094048</td>\n",
       "      <td>2441.085119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annee  cum_rr_end_year  cum_tm_end_year  cum_tx_end_year  cum_tn_end_year\n",
       "0   1950      1354.693791          4973.35      6319.083333      2722.300000\n",
       "1   1951      1537.841796          4766.50      5870.350000      2546.475000\n",
       "2   1952      1583.263803          4852.20      6059.233333      2542.516667\n",
       "3   1953       915.175000          4638.45      6016.910000      2443.906667\n",
       "4   1954      1498.891898          4490.85      5693.094048      2441.085119"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex√©cution de la requ√™te\n",
    "df = run_query(\"\"\" WITH daily_avg AS (\n",
    "  SELECT \n",
    "    CAST(SUBSTRING(\"AAAAMMJJ\", 1, 4) AS INTEGER) AS annee,\n",
    "    CAST(SUBSTRING(\"AAAAMMJJ\", 5, 2) AS INTEGER) AS mois,\n",
    "    CAST(SUBSTRING(\"AAAAMMJJ\", 7, 2) AS INTEGER) AS jour,\n",
    "    AVG(CAST(\"RR\" AS DOUBLE)) AS avg_rr,\n",
    "    AVG(CAST(\"TM\" AS DOUBLE)) AS avg_tm,\n",
    "    AVG(CAST(\"TX\" AS DOUBLE)) AS avg_tx,\n",
    "    AVG(CAST(\"TN\" AS DOUBLE)) AS avg_tn\n",
    "  FROM \n",
    "    loaded_dataset\n",
    "  GROUP BY \n",
    "    annee, mois, jour\n",
    "),\n",
    "cum_sum AS (\n",
    "  SELECT \n",
    "    annee,\n",
    "    jour_de_annee,\n",
    "    SUM(avg_rr) OVER (PARTITION BY annee ORDER BY jour_de_annee) AS cum_rr,\n",
    "    SUM(avg_tm) OVER (PARTITION BY annee ORDER BY jour_de_annee) AS cum_tm,\n",
    "    SUM(avg_tx) OVER (PARTITION BY annee ORDER BY jour_de_annee) AS cum_tx,\n",
    "    SUM(avg_tn) OVER (PARTITION BY annee ORDER BY jour_de_annee) AS cum_tn\n",
    "  FROM (\n",
    "    SELECT \n",
    "      annee,\n",
    "      (mois - 1) * 30 + jour AS jour_de_annee,\n",
    "      avg_rr,\n",
    "      avg_tm,\n",
    "      avg_tx,\n",
    "      avg_tn\n",
    "    FROM \n",
    "      daily_avg\n",
    "  ) AS subquery\n",
    ")\n",
    "SELECT \n",
    "  annee,\n",
    "  cum_rr AS cum_rr_end_year,\n",
    "  cum_tm AS cum_tm_end_year,\n",
    "  cum_tx AS cum_tx_end_year,\n",
    "  cum_tn AS cum_tn_end_year\n",
    "FROM \n",
    "  cum_sum\n",
    "WHERE \n",
    "  jour_de_annee = (SELECT MAX(jour_de_annee) FROM cum_sum AS cs WHERE cs.annee = cum_sum.annee)\n",
    "ORDER BY \n",
    "  annee \"\"\")\n",
    "print(f\"R√©sultats : {len(df)} lignes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualisation\n",
    "\n",
    "La biblioth√®que principale utilis√©e pour cette visualisation est Seaborn, une extension de Matplotlib, qui permet de cr√©er des graphiques statistiques attractifs et informatifs. Ce choix est adapt√© car Seaborn offre une grande flexibilit√© pour personnaliser les visualisations et Matplotlib fournit une base solide pour les repr√©sentations graphiques. Cela permet une repr√©sentation claire et concise de l'√©volution des composantes m√©t√©orologiques cumul√©es par ann√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:00:28.738046Z",
     "iopub.status.busy": "2025-08-21T10:00:28.738046Z",
     "iopub.status.idle": "2025-08-21T10:00:29.801930Z",
     "shell.execute_reply": "2025-08-21T10:00:29.801930Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrMethodFormatter\n\u001b[0;32m      9\u001b[0m palette \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcum_rr_end_year\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#add8e6\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# light blue : pluie\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcum_tm_end_year\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#ffd700\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# gold       : temp√©rature moyenne\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcum_tx_end_year\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#ff4500\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# orangered  : temp√©rature max\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcum_tn_end_year\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#4682b4\u001b[39m\u001b[38;5;124m\"\u001b[39m    \u001b[38;5;66;03m# steelblue  : temp√©rature min\u001b[39;00m\n\u001b[0;32m     14\u001b[0m }\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb as ddb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "palette = {\n",
    "    \"cum_rr_end_year\": \"#add8e6\",   # light blue : pluie\n",
    "    \"cum_tm_end_year\": \"#ffd700\",   # gold       : temp√©rature moyenne\n",
    "    \"cum_tx_end_year\": \"#ff4500\",   # orangered  : temp√©rature max\n",
    "    \"cum_tn_end_year\": \"#4682b4\"    # steelblue  : temp√©rature min\n",
    "}\n",
    "\n",
    "# Lissage sur 10 ans (fen√™tre glissante centr√©e, dropna pour nettoyer)\n",
    "window = 10\n",
    "df_plot = df.copy()\n",
    "for col in [\"cum_rr_end_year\", \"cum_tm_end_year\", \"cum_tx_end_year\", \"cum_tn_end_year\"]:\n",
    "    df_plot[f\"{col}_smooth\"] = df_plot[col].rolling(window, center=True).mean()\n",
    "\n",
    "df_plot = df_plot.dropna(subset=[f\"{col}_smooth\" for col in palette.keys()])\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"DejaVu Sans\",\n",
    "    \"font.size\": 11,\n",
    "})\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "labels = {\n",
    "    \"cum_rr_end_year\": \"Cumul pr√©cipitations (mm)\",\n",
    "    \"cum_tm_end_year\": \"Cumul T moyenne (¬∞C)\",\n",
    "    \"cum_tx_end_year\": \"Cumul T max (¬∞C)\",\n",
    "    \"cum_tn_end_year\": \"Cumul T min (¬∞C)\",\n",
    "}\n",
    "\n",
    "for idx, col in enumerate(palette.keys()):\n",
    "    ax = axes[idx]\n",
    "    ax.plot(\n",
    "        df_plot[\"annee\"],\n",
    "        df_plot[col],\n",
    "        color=palette[col],\n",
    "        linewidth=1.5,\n",
    "        alpha=0.7,\n",
    "        label=\"Donn√©es brutes (rouge clair)\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        df_plot[\"annee\"],\n",
    "        df_plot[f\"{col}_smooth\"],\n",
    "        color=\"blue\",\n",
    "        linewidth=2.5,\n",
    "        label=\"Courbe liss√©e (10 ans)\",\n",
    "    )\n",
    "    ax.set_title(labels[col], fontsize=14, weight=\"bold\")\n",
    "    ax.set_xlabel(\"Ann√©e\")\n",
    "    ax.set_ylabel(\"Valeur cumul√©e\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:,.0f}\"))\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "plt.suptitle(\"√âvolution des composantes m√©t√©orologiques cumul√©es par ann√©e\", fontsize=16)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "dataviz = fig\n",
    "dataviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T10:00:29.801930Z",
     "iopub.status.busy": "2025-08-21T10:00:29.801930Z",
     "iopub.status.idle": "2025-08-21T10:00:30.280376Z",
     "shell.execute_reply": "2025-08-21T10:00:30.280376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVERTISSEMENT: Aucune variable 'dataviz' trouv√©e.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Variables inject√©es par le script ---\n",
    "FINAL_OBJECT_VARIABLE_NAME = 'dataviz'\n",
    "OUTPUT_IMAGE_NAME = 'published\\\\notebooks\\\\duckit_analysis_20250820_223026.png'\n",
    "OUTPUT_HTML_NAME = 'published\\\\notebooks\\\\duckit_analysis_20250820_223026.html'\n",
    "\n",
    "# ===================================================================\n",
    "# CELLULE INJECT√âE AUTOMATIQUEMENT (VERSION ROBUSTE)\n",
    "# ===================================================================\n",
    "import sys\n",
    "import os\n",
    "# On importe les modules n√©cessaires pour l'export au cas o√π\n",
    "try:\n",
    "    from bokeh.io import save as bokeh_save\n",
    "except ImportError:\n",
    "    bokeh_save = None\n",
    "\n",
    "try:\n",
    "    # On s'assure que le dossier de sortie existe\n",
    "    output_dir = os.path.dirname(OUTPUT_IMAGE_NAME)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # On utilise globals().get() pour une r√©cup√©ration plus s√ªre\n",
    "    final_object = globals().get(FINAL_OBJECT_VARIABLE_NAME)\n",
    "\n",
    "    if final_object is None:\n",
    "        # On l√®ve une NameError pour √™tre coh√©rent avec le code original\n",
    "        raise NameError(f\"name '{FINAL_OBJECT_VARIABLE_NAME}' is not defined\")\n",
    "\n",
    "    print(f\"INFO: Variable '{FINAL_OBJECT_VARIABLE_NAME}' trouv√©e. Tentative d'exportation...\")\n",
    "\n",
    "    object_type = str(type(final_object))\n",
    "\n",
    "    if 'plotly.graph_objs._figure.Figure' in object_type:\n",
    "        print(f\"--> D√©tect√© : Plotly. Sauvegarde HTML et PNG.\")\n",
    "        # 1. Sauvegarde HTML pour l'interactivit√©\n",
    "        print(f\"--> Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.write_html(OUTPUT_HTML_NAME, include_plotlyjs='cdn')\n",
    "        # 2. Sauvegarde PNG pour l'aper√ßu statique\n",
    "        try:\n",
    "            print(f\"--> Tentative de sauvegarde PNG directe dans : {OUTPUT_IMAGE_NAME}\")\n",
    "            final_object.write_image(OUTPUT_IMAGE_NAME, scale=3, width=1200, height=800)\n",
    "            print(f\"--> Image Plotly sauvegard√©e avec succ√®s.\")\n",
    "        except Exception as e:\n",
    "            print(f\"AVERTISSEMENT: La sauvegarde directe en PNG a √©chou√© (kaleido est-il install√©?).\", file=sys.stderr)\n",
    "            print(f\"   Erreur: {e}\", file=sys.stderr)\n",
    "            print(f\"--> PLAN B: On va utiliser la capture d'√©cran du HTML √† la place.\")\n",
    "            # On cr√©e un fichier marqueur pour que le script de post-traitement prenne le relais\n",
    "            with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "                f.write(\"plotly\")\n",
    "    elif 'folium.folium.Map' in object_type:\n",
    "        print(f\"--> D√©tect√© : Folium. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.save(OUTPUT_HTML_NAME)\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"folium\")\n",
    "    elif 'altair.vegalite' in object_type and hasattr(final_object, 'save'):\n",
    "        print(f\"--> D√©tect√© : Altair. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.save(OUTPUT_HTML_NAME)\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"altair\")\n",
    "    elif 'bokeh.plotting' in object_type and bokeh_save is not None:\n",
    "        print(f\"--> D√©tect√© : Bokeh. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        bokeh_save(final_object, filename=OUTPUT_HTML_NAME, title=\"\")\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"bokeh\")\n",
    "    elif 'matplotlib.figure.Figure' in object_type:\n",
    "        print(f\"--> D√©tect√© : Matplotlib. Sauvegarde dans : {OUTPUT_IMAGE_NAME}\")\n",
    "        final_object.savefig(OUTPUT_IMAGE_NAME, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        print(f\"AVERTISSEMENT: Type non support√© : {object_type}\", file=sys.stderr)\n",
    "except NameError:\n",
    "    print(f\"AVERTISSEMENT: Aucune variable '{FINAL_OBJECT_VARIABLE_NAME}' trouv√©e.\", file=sys.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR lors de l'exportation : {e}\", file=sys.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "5748ebf7fbd74f75b31cbb765b13ab49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e47bbb7f31145e5bf1884181d42e6c7",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_eacc4b9ed67e49ffb57bce0ff17877c2",
       "tabbable": null,
       "tooltip": null,
       "value": 100.0
      }
     },
     "5e47bbb7f31145e5bf1884181d42e6c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "eacc4b9ed67e49ffb57bce0ff17877c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
