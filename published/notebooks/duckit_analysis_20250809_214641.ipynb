{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cartographie des Projets France2030 : Une Analyse G√©ographique des Financements ADEME\n",
        "\n",
        "L'analyse pr√©sent√©e dans ce notebook s'appuie sur un jeu de donn√©es provenant de l'ADEME (Agence de l'environnement et de la ma√Ætrise de l'√©nergie) concernant les projets financ√©s dans le cadre de France2030. Le fichier source, disponible √† l'adresse https://data.ademe.fr/data-fair/api/v1/datasets/zb29czhpiv4na0do47l6lmmg/lines?size=10000&page=1&format=csv, contient des informations d√©taill√©es sur les projets, notamment leur √©tat d'avancement, les montants financiers impliqu√©s, ainsi que les coordonn√©es g√©ographiques des lieux principaux.\n",
        "\n",
        "L'objectif principal de cette analyse est de pr√©parer les donn√©es pour une visualisation cartographique qui met en √©vidence la r√©partition g√©ographique des projets √† travers la France. Plus pr√©cis√©ment, il s'agit de cr√©er une carte avec un choropleth des d√©partements en fond de plan, en calculant le nombre de projets par d√©partement et en incluant les coordonn√©es g√©ographiques des projets individuels.\n",
        "\n",
        "## M√©thodologie\n",
        "\n",
        "La m√©thodologie employ√©e pour cette analyse repose sur l'utilisation de DuckDB pour le traitement des donn√©es et de Plotly Express pour la visualisation. Tout d'abord, les donn√©es sont charg√©es et trait√©es √† l'aide d'une requ√™te SQL qui calcule le nombre de projets par d√©partement et extrait les coordonn√©es g√©ographiques des projets. Ensuite, les r√©sultats sont utilis√©s pour cr√©er une carte choropl√®the des d√©partements avec des marqueurs repr√©sentant les projets individuels.\n",
        "\n",
        "\n",
        "Cette approche permet de combiner efficacement l'analyse de donn√©es et la visualisation pour offrir une repr√©sentation claire et informative de la r√©partition g√©ographique des projets financ√©s par l'ADEME dans le cadre de France2030.\n",
        "\n",
        " \n",
        "\n",
        "Le contenu de ce notebook est disponible sous forme de sections d√©taill√©es qui exposent chaque √©tape de l'analyse, de la pr√©paration des donn√©es √† la visualisation finale. Des explications d√©taill√©es sont fournies pour chaque √©tape, ce qui facilite la compr√©hension et la reproduction de l'analyse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation et imports\n",
        "import duckdb as ddb\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü¶Ü Chargement du dataset avec Duckdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
        "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
        "    ddb.execute(\"install spatial\")\n",
        "    ddb.execute(\"load spatial\")\n",
        "    ddb.execute(\"INSTALL h3 FROM community\")\n",
        "    ddb.execute(\"LOAD h3\")\n",
        "    ddb.execute(\"install webbed from community;\")\n",
        "    ddb.execute(\"load webbed\")\n",
        "    ddb.execute(\"set force_download=True\")\n",
        "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
        "    \n",
        "    # D√©tection automatique du type de fichier\n",
        "    if 'csv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'tsv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'txt' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'parquet' in url_dataset: \n",
        "        loader = \"read_parquet\"\n",
        "    elif 'json' in url_dataset: \n",
        "        loader = \"read_json_auto\"\n",
        "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'shp' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'geojson' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'xml' in url_dataset: \n",
        "        loader = \"read_xml\"\n",
        "    elif 'html' in url_dataset: \n",
        "        loader = \"read_html\"\n",
        "    else: \n",
        "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
        "    \n",
        "    if options==\"\": \n",
        "        options = \"\" \n",
        "    if 'csv' in url_dataset and safe_mode==True: \n",
        "        options = \", all_varchar=1\" \n",
        "    if nom_table==\"\": \n",
        "        nom_table = \"loaded_dataset\"\n",
        "    \n",
        "    try:\n",
        "        status = ddb.sql(f\"\"\"\n",
        "            create or replace table {nom_table} as select *\n",
        "            from\n",
        "            {loader}(\"{url_dataset}\" {options})\n",
        "        \"\"\")\n",
        "        return status\n",
        "    except Exception as e:\n",
        "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
        "\n",
        "def run_query(sql):\n",
        "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
        "\n",
        "# Chargement des donn√©es\n",
        "load_file_from_url_lite(\"https://data.ademe.fr/data-fair/api/v1/datasets/zb29czhpiv4na0do47l6lmmg/lines?size=10000&page=1&format=csv\", safe_mode=True)\n",
        "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Analyse SQL\n",
        "\n",
        "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ex√©cution de la requ√™te\n",
        "df = run_query(\"\"\" WITH departement_projects AS (\n",
        " SELECT \n",
        " SUBSTRING(\"Lieu principal d√©partement code\",1,2) AS code_dept,\n",
        " COUNT(*) AS nb_projets_dept\n",
        " FROM \n",
        " loaded_dataset\n",
        " GROUP BY \n",
        " SUBSTRING(\"Lieu principal d√©partement code\",1,2)\n",
        "),\n",
        "project_data AS (\n",
        " SELECT \n",
        " SUBSTRING(\"Lieu principal d√©partement code\",1,2) AS code_dept,\n",
        " \"Nom du projet\" AS description_projet,\n",
        " CAST(\"Lieu principal commune longitude (X)\" AS DOUBLE) AS x_projet,\n",
        " CAST(\"Lieu principal commune latitude (Y)\" AS DOUBLE) AS y_projet\n",
        " FROM \n",
        " loaded_dataset\n",
        ")\n",
        "SELECT \n",
        " pd.code_dept,\n",
        " dp.nb_projets_dept,\n",
        " pd.description_projet,\n",
        " pd.x_projet,\n",
        " pd.y_projet\n",
        "FROM \n",
        " project_data pd\n",
        "LEFT JOIN departement_projects dp ON pd.code_dept = dp.code_dept\n",
        "ORDER BY \n",
        " pd.code_dept \"\"\")\n",
        "print(f\"R√©sultats : {len(df)} lignes\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualisation\n",
        "\n",
        "La biblioth√®que principale utilis√©e est Plotly Express, qui permet de cr√©er des visualisations interactives et attractives. Cette technologie est adapt√©e pour repr√©senter des donn√©es g√©ographiques, comme ici une carte choropl√®the des d√©partements fran√ßais et des marqueurs de projets, gr√¢ce √† ses fonctionnalit√©s de cartographie avanc√©es. Cela permet une exploration intuitive des donn√©es."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import duckdb as ddb\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import json\n",
        "import requests\n",
        "\n",
        "# T√©l√©chargement du GeoJSON des d√©partements\n",
        "url = 'https://france-geojson.gregoiredavid.fr/repo/departements.geojson'\n",
        "resp = requests.get(url)\n",
        "geojson_dept = resp.json()\n",
        "\n",
        "# DataFrame d√©partement / nombre de projets uniques\n",
        "dept_proj = df[['code_dept','nb_projets_dept']].drop_duplicates('code_dept')\n",
        "\n",
        "# Carte choropl√®the des d√©partements\n",
        "fig = px.choropleth_mapbox(\n",
        "    dept_proj,\n",
        "    geojson=geojson_dept,\n",
        "    locations='code_dept',\n",
        "    featureidkey='properties.code',\n",
        "    color='nb_projets_dept',\n",
        "    color_continuous_scale='YlGnBu',\n",
        "    mapbox_style='carto-positron',\n",
        "    zoom=4.3,\n",
        "    center={'lat':46.5,'lon':2.5},\n",
        "    opacity=0.65,\n",
        "    labels={'nb_projets_dept':'Nb projets<br>ADEME'}\n",
        ")\n",
        "\n",
        "# Filtre lat/lon pour rester en m√©tropole\n",
        "mask = (\n",
        "    (df['y_projet'] >= 41) & (df['y_projet'] <= 52) &\n",
        "    (df['x_projet'] >= -6) & (df['x_projet'] <= 10)\n",
        ")\n",
        "df_ = df[mask].copy()\n",
        "\n",
        "# Marqueurs des projets\n",
        "scatter = px.scatter_mapbox(\n",
        "    df_,\n",
        "    lat='y_projet',\n",
        "    lon='x_projet',\n",
        "    hover_name='description_projet',\n",
        "    hover_data={'y_projet':False,'x_projet':False},\n",
        "    opacity=0.9,\n",
        "    color_discrete_sequence=['#ff4b4b']\n",
        ")\n",
        "for trace in scatter.data:\n",
        "    fig.add_trace(trace)\n",
        "\n",
        "fig.update_layout(\n",
        "    title={\n",
        "        'text':'France2030 ‚Äì Projets financ√©s par l‚ÄôADEME',\n",
        "        'x':0.5,\n",
        "        'xanchor':'center',\n",
        "        'font':{'size':18,'family':'Roboto'}\n",
        "    },\n",
        "    margin={'l':20,'r':20,'t':50,'b':20},\n",
        "    height=650\n",
        ")\n",
        "\n",
        "dataviz = fig\n",
        "dataviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}