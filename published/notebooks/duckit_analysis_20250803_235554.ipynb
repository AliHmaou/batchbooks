{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî• Au-del√† de la tol√©rance : cartographier les exc√®s de vitesse extr√™mes en France\n",
        "\n",
        "L‚Äôensemble des **12,8 millions** de prises de vitesse instantan√©es r√©alis√©es en 2023 par les ¬´ voitures-radars ¬ª du r√©seau national trace, minute-par-minute, une radioscopie sans pr√©c√©dent du comportement des automobilistes fran√ßais.  \n",
        "Acc√©dez **directement aux donn√©es brutes** sur data.gouv.fr via : [https://static.data.gouv.fr/resources/jeux-de-donnees-des-vitesses-relevees-par-les-voitures-radars-a-conduite-externalisee/20241029-142313/opendata-vitesses-pratiquees-voitures-radars-2023-01-01-2023-12-31-.csv](https://static.data.gouv.fr/resources/jeux-de-donnees-des-vitesses-relevees-par-les-voitures-radars-a-conduite-externalisee/20241029-142313/opendata-vitesses-pratiquees-voitures-radars-2023-01-01-2023-12-31-.csv).  \n",
        "Ce jeu de donn√©es regroupe pour chaque mesure : date/heure pr√©cise (format `YYYY-MM-DD hh:mm`), coordonn√©es GPS (lat, lon), vitesse mesur√©e et limite th√©orique du tron√ßon. L‚Äôobjectif ici est cibl√© : isoler les situations o√π la vitesse mesur√©e d√©passe la vitesse autoris√©e **de plus de 50 km/h**, un seuil au-del√† duquel l‚Äôexc√®s est consid√©r√© comme **dangereusement critique**. En restituant la localisation exacte de ces √©v√©nements, nous cr√©ons une carte de chaleur interactive pour **identifier les zones o√π le risque routier culminera avant qu‚Äôun drame ne survienne** ‚Äì un outil directement mobilisable pour les √©lus, les services d√©partementaux de s√©curit√©, ou les associations de victimes.\n",
        "\n",
        "## M√©thodologie\n",
        "\n",
        "L‚Äôanalyse s‚Äôappuie sur DuckDB, un moteur SQL ¬´ on-the-fly ¬ª performant sur fichiers CSV volumineux.  \n",
        "1. **Filtrage statique** : requ√™te SQL (`SELECT ... WHERE mesure - limite > 50`) pour extraire les 10 000 premi√®res observations class√©es par d√©passement d√©croissant.  \n",
        "2. **Parsing GPS** : conversion en champs `latitude`, `longitude` √† l‚Äôaide de `split_part`.  \n",
        "3. **Projection cartographique** : le centrage de la carte dynamique est automatiquement calcul√© sur la moyenne des points g√©olocalis√©s, puis une **HeatMap Folium** (rayon 15 m, flou 10 m, opacit√© min 0,6) est superpos√©e pour rendre l‚Äôintensit√© de l‚Äôextr√™me visible d‚Äôun seul coup d‚Äô≈ìil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation et imports\n",
        "import duckdb as ddb\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü¶Ü Chargement du dataset avec Duckdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
        "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
        "    ddb.execute(\"install spatial\")\n",
        "    ddb.execute(\"load spatial\")\n",
        "    ddb.execute(\"INSTALL h3 FROM community\")\n",
        "    ddb.execute(\"LOAD h3\")\n",
        "    ddb.execute(\"install webbed from community;\")\n",
        "    ddb.execute(\"load webbed\")\n",
        "    ddb.execute(\"set force_download=True\")\n",
        "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
        "    \n",
        "    # D√©tection automatique du type de fichier\n",
        "    if 'csv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'tsv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'txt' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'parquet' in url_dataset: \n",
        "        loader = \"read_parquet\"\n",
        "    elif 'json' in url_dataset: \n",
        "        loader = \"read_json_auto\"\n",
        "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'shp' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'geojson' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'xml' in url_dataset: \n",
        "        loader = \"read_xml\"\n",
        "    elif 'html' in url_dataset: \n",
        "        loader = \"read_html\"\n",
        "    else: \n",
        "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
        "    \n",
        "    if options==\"\": \n",
        "        options = \"\" \n",
        "    if 'csv' in url_dataset and safe_mode==True: \n",
        "        options = \", all_varchar=1\" \n",
        "    if nom_table==\"\": \n",
        "        nom_table = \"loaded_dataset\"\n",
        "    \n",
        "    try:\n",
        "        status = ddb.sql(f\"\"\"\n",
        "            create or replace table {nom_table} as select *\n",
        "            from\n",
        "            {loader}(\"{url_dataset}\" {options})\n",
        "        \"\"\")\n",
        "        return status\n",
        "    except Exception as e:\n",
        "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
        "\n",
        "def run_query(sql):\n",
        "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
        "\n",
        "# Chargement des donn√©es\n",
        "load_file_from_url_lite(\"https://static.data.gouv.fr/resources/jeux-de-donnees-des-vitesses-relevees-par-les-voitures-radars-a-conduite-externalisee/20241029-142313/opendata-vitesses-pratiquees-voitures-radars-2023-01-01-2023-12-31-.csv\", safe_mode=True)\n",
        "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Analyse SQL\n",
        "\n",
        "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ex√©cution de la requ√™te\n",
        "df = run_query(\"\"\" SELECT \n",
        "    substr(\"date\",1,10) as date_mesure,\n",
        "    split_part(\"position\",' ',1) as latitude,\n",
        "    split_part(\"position\",' ',2) as longitude,\n",
        "    cast(\"mesure\" as double) - cast(\"limite\" as double) as depassement_kmh\n",
        "FROM loaded_dataset\n",
        "WHERE cast(\"mesure\" as double) - cast(\"limite\" as double) > 50\n",
        "ORDER BY depassement_kmh DESC\n",
        "LIMIT 10000 \"\"\")\n",
        "print(f\"R√©sultats : {len(df)} lignes\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualisation\n",
        "\n",
        "Cette carte de chaleur a √©t√© r√©alis√©e avec la biblioth√®que Folium, qui combine la puissance de Leaflet.js et la simplicit√© de Python pour produire des cartes web interactives. Elle permet de visualiser instantan√©ment les zones o√π le d√©passement de vitesse est le plus critique, en exploitant la densit√© de points GPS comme intensit√© de couleur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import duckdb as ddb\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "\n",
        "df_exces = df[df['depassement_kmh'] > 50].copy()\n",
        "df_exces[['latitude', 'longitude']] = df_exces[['latitude', 'longitude']].astype(float)\n",
        "\n",
        "center_lat = df_exces['latitude'].mean()\n",
        "center_lon = df_exces['longitude'].mean()\n",
        "\n",
        "dataviz = folium.Map(location=[center_lat, center_lon], zoom_start=6)\n",
        "HeatMap(df_exces[['latitude', 'longitude']], radius=15, blur=10, min_opacity=0.6).add_to(dataviz)\n",
        "dataviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}