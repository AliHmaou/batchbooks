{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cartographie de la Temp√©rature Moyenne des Postes M√©t√©o en France\n",
        "\n",
        "\n",
        "Le pr√©sent notebook est consacr√© √† l'analyse et √† la visualisation des donn√©es m√©t√©orologiques issues de divers postes de mesure en France. Les donn√©es utilis√©es proviennent du fichier `Q_64_previous-1950-2023_RR-T-Vent.csv.gz`, disponible √† l'adresse https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_64_previous-1950-2023_RR-T-Vent.csv.gz. Ce fichier contient des informations m√©t√©orologiques recueillies √† partir de divers postes de mesure, notamment la temp√©rature, les pr√©cipitations, et la vitesse du vent.\n",
        "\n",
        "\n",
        "L'objectif de cette analyse est de pr√©parer les donn√©es pour une carte repr√©sentant les postes de mesure avec leur temp√©rature moyenne respective. Cette visualisation permettra d'appr√©hender la r√©partition g√©ographique des temp√©ratures moyennes en France.\n",
        "\n",
        "\n",
        "## M√©thodologie\n",
        "\n",
        "La m√©thodologie employ√©e pour cette analyse comporte plusieurs √©tapes cl√©s. Tout d'abord, les donn√©es sont charg√©es et nettoy√©es. Ensuite, une requ√™te SQL est ex√©cut√©e via DuckDB pour agr√©ger les donn√©es par poste de mesure et calculer la moyenne de la temp√©rature moyenne (`TM`) pour chaque ann√©e. Les r√©sultats sont ensuite utilis√©s pour cr√©er une visualisation interactive sous forme de carte utilisant la biblioth√®que Folium. Les postes de mesure sont repr√©sent√©s par des cercles dont la couleur est fonction de la temp√©rature moyenne enregistr√©e.\n",
        "\n",
        "\n",
        "Les donn√©es sont ainsi analys√©es et repr√©sent√©es de mani√®re √† offrir une vue d'ensemble claire et intuitive de la r√©partition des temp√©ratures moyennes en France. Cette visualisation facilite l'identification des tendances et des disparit√©s r√©gionales en mati√®re de temp√©rature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation et imports\n",
        "import duckdb as ddb\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü¶Ü Chargement du dataset avec Duckdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
        "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
        "    ddb.execute(\"install spatial\")\n",
        "    ddb.execute(\"load spatial\")\n",
        "    ddb.execute(\"INSTALL h3 FROM community\")\n",
        "    ddb.execute(\"LOAD h3\")\n",
        "    ddb.execute(\"set force_download=True\")\n",
        "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
        "    \n",
        "    # D√©tection automatique du type de fichier\n",
        "    if 'csv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'tsv' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'txt' in url_dataset: \n",
        "        loader = \"read_csv_auto\"\n",
        "    elif 'parquet' in url_dataset: \n",
        "        loader = \"read_parquet\"\n",
        "    elif 'json' in url_dataset: \n",
        "        loader = \"read_json_auto\"\n",
        "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'shp' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    elif 'geojson' in url_dataset: \n",
        "        loader = \"st_read\"\n",
        "    else: \n",
        "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
        "    \n",
        "    if options==\"\": \n",
        "        options = \"\" \n",
        "    if 'csv' in url_dataset and safe_mode==True: \n",
        "        options = \", all_varchar=1\" \n",
        "    if nom_table==\"\": \n",
        "        nom_table = \"loaded_dataset\"\n",
        "    \n",
        "    try:\n",
        "        status = ddb.sql(f\"\"\"\n",
        "            create or replace table {nom_table} as select *\n",
        "            from\n",
        "            {loader}(\"{url_dataset}\" {options})\n",
        "        \"\"\")\n",
        "        return status\n",
        "    except Exception as e:\n",
        "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
        "\n",
        "def run_query(sql):\n",
        "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
        "\n",
        "# Chargement des donn√©es\n",
        "load_file_from_url_lite(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_64_previous-1950-2023_RR-T-Vent.csv.gz\", safe_mode=True)\n",
        "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Analyse SQL\n",
        "\n",
        "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ex√©cution de la requ√™te\n",
        "df = run_query(\"\"\" SELECT \n",
        "  CAST(SUBSTRING(\"AAAAMMJJ\", 1, 4) AS INTEGER) AS year,\n",
        "  \"NUM_POSTE\",\n",
        "  CAST(\"LON\" AS DOUBLE) AS longitude,\n",
        "  CAST(\"LAT\" AS DOUBLE) AS latitude,\n",
        "  AVG(CAST(\"TM\" AS DOUBLE)) AS avg_TM\n",
        "FROM \n",
        "  loaded_dataset\n",
        "WHERE \n",
        "  \"TM\" IS NOT NULL\n",
        "GROUP BY \n",
        "  \"NUM_POSTE\", \"LON\", \"LAT\", CAST(SUBSTRING(\"AAAAMMJJ\", 1, 4) AS INTEGER)\n",
        "ORDER BY \n",
        "  year \"\"\")\n",
        "print(f\"R√©sultats : {len(df)} lignes\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualisation\n",
        "\n",
        "La biblioth√®que principale utilis√©e est Folium, qui est une surcouche de Leaflet.js permettant de cr√©er des cartes interactives. Cette technologie est adapt√©e pour repr√©senter des donn√©es g√©olocalis√©es avec des marqueurs et des informations associ√©es, comme c'est le cas ici avec les temp√©ratures moyennes par poste. Folium permet de cr√©er une visualisation interactive et intuitive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import duckdb as ddb\n",
        "import folium\n",
        "import branca.colormap as cm\n",
        "\n",
        "color_scale = cm.LinearColormap(colors=['dodgerblue', 'orangered'],\n",
        "                                 index=[df['avg_TM'].min(), df['avg_TM'].max()],\n",
        "                                 vmin=df['avg_TM'].min(), vmax=df['avg_TM'].max(),\n",
        "                                 caption='Temp√©rature moyenne (¬∞C)')\n",
        "\n",
        "# ordre croissant pour superposer les plus froid en-dessous\n",
        "coords = df[['latitude', 'longitude', 'NUM_POSTE', 'avg_TM']].sort_values('avg_TM')\n",
        "\n",
        "m = folium.Map(location=[coords.latitude.mean(), coords.longitude.mean()],\n",
        "               tiles='CartoDB positron', zoom_start=8)\n",
        "\n",
        "for _, row in coords.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row.latitude, row.longitude],\n",
        "        radius=6,\n",
        "        color='black',\n",
        "        weight=0.5,\n",
        "        fillColor=color_scale(row.avg_TM),\n",
        "        fillOpacity=0.85,\n",
        "        popup=None,\n",
        "        tooltip=f\"<b>Poste&nbsp;n¬∞{int(row.NUM_POSTE)}</b><br>{row.avg_TM:.2f}¬∞C\"\n",
        "    ).add_to(m)\n",
        "\n",
        "color_scale.add_to(m)\n",
        "\n",
        "dataviz = m\n",
        "dataviz.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}