{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Pr√©cipitations Annuelles Cumul√©es : Une Exploration des Donn√©es M√©t√©o de M√©t√©o France\n",
    "\n",
    "\n",
    "Les donn√©es m√©t√©orologiques constituent une ressource pr√©cieuse pour comprendre les tendances climatiques et les ph√©nom√®nes m√©t√©orologiques qui affectent notre plan√®te. Dans ce notebook, nous allons explorer le fichier de donn√©es m√©t√©o fourni par M√©t√©o France, qui contient des informations quotidiennes sur les pr√©cipitations, les temp√©ratures et d'autres variables m√©t√©orologiques pour divers postes en France, couvrant une p√©riode allant de 1950 √† 2023. Le fichier source est disponible √† l'adresse suivante : https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_64_previous-1950-2023_RR-T-Vent.csv.gz.\n",
    "\n",
    "L'objectif de cette analyse est de calculer la somme cumulative des pr√©cipitations journali√®res moyennes sur toutes les stations √† la mani√®re d'une int√©grale depuis le d√©but de chaque ann√©e et de ne garder que la valeur de fin de chaque ann√©e. Cela nous permettra de comprendre l'√©volution des pr√©cipitations annuelles cumul√©es sur la p√©riode √©tudi√©e et d'identifier les tendances et les variations significatives.\n",
    "\n",
    "\n",
    "## M√©thodologie\n",
    "\n",
    "Pour atteindre cet objectif, nous allons utiliser la biblioth√®que DuckDB pour traiter les donn√©es et effectuer les calculs n√©cessaires. Nous allons d'abord charger les donn√©es dans DuckDB, puis nous allons utiliser une requ√™te SQL pour calculer la moyenne des pr√©cipitations journali√®res par jour, suivie d'un calcul de la somme cumulative de ces moyennes par ann√©e. Nous allons ensuite utiliser Python et les biblioth√®ques Matplotlib et Pandas pour visualiser les r√©sultats et mettre en √©vidence les tendances et les variations dans les pr√©cipitations annuelles cumul√©es.\n",
    "\n",
    "\n",
    "## R√©sultats\n",
    "\n",
    "Les r√©sultats de l'analyse seront pr√©sent√©s sous forme de graphique, montrant l'√©volution des pr√©cipitations annuelles cumul√©es sur la p√©riode √©tudi√©e, ainsi que la courbe liss√©e sur 20 ans pour mettre en √©vidence les tendances √† long terme.\n",
    "\n",
    "\n",
    "## Visualisation\n",
    "\n",
    "La visualisation des r√©sultats sera effectu√©e √† l'aide de Matplotlib, avec une mise en forme soign√©e pour faciliter la lecture et l'interpr√©tation des donn√©es.\n",
    "\n",
    "\n",
    "Ce notebook Jupyter est con√ßu pour √™tre une ressource informative et p√©dagogique, accessible √† un public int√©ress√© par l'analyse de donn√©es et les sciences de l'environnement. Nous esp√©rons qu'il inspirera les lecteurs √† explorer davantage les donn√©es m√©t√©orologiques et √† approfondir leur compr√©hension des ph√©nom√®nes climatiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T09:59:35.331196Z",
     "iopub.status.busy": "2025-08-21T09:59:35.331196Z",
     "iopub.status.idle": "2025-08-21T09:59:35.903258Z",
     "shell.execute_reply": "2025-08-21T09:59:35.903258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Installation et imports\n",
    "import duckdb as ddb\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü¶Ü Chargement du dataset avec Duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T09:59:35.903258Z",
     "iopub.status.busy": "2025-08-21T09:59:35.903258Z",
     "iopub.status.idle": "2025-08-21T09:59:46.830323Z",
     "shell.execute_reply": "2025-08-21T09:59:46.830323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51557c126f94822a425dbe9e4365dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# Fonction de chargement compl√®te (bas√©e sur load_file_from_url_lite)\n",
    "def load_file_from_url_lite(url_dataset=\"\", loader=\"read_csv_auto\", options=\"\", nom_table=\"loaded_dataset\", safe_mode=False):\n",
    "    ddb.execute(\"install spatial\")\n",
    "    ddb.execute(\"load spatial\")\n",
    "    ddb.execute(\"INSTALL h3 FROM community\")\n",
    "    ddb.execute(\"LOAD h3\")\n",
    "    ddb.execute(\"install webbed from community;\")\n",
    "    ddb.execute(\"load webbed\")\n",
    "    ddb.execute(\"set force_download=True\")\n",
    "    ddb.execute(f\"drop table if exists {nom_table}\")   \n",
    "    \n",
    "    # D√©tection automatique du type de fichier\n",
    "    if 'csv' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'tsv' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'txt' in url_dataset: \n",
    "        loader = \"read_csv_auto\"\n",
    "    elif 'parquet' in url_dataset: \n",
    "        loader = \"read_parquet\"\n",
    "    elif 'json' in url_dataset: \n",
    "        loader = \"read_json_auto\"\n",
    "    elif 'xls' in url_dataset or 'xlsx' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'shp' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'geojson' in url_dataset: \n",
    "        loader = \"st_read\"\n",
    "    elif 'xml' in url_dataset: \n",
    "        loader = \"read_xml\"\n",
    "    elif 'html' in url_dataset: \n",
    "        loader = \"read_html\"\n",
    "    else: \n",
    "        raise ValueError(f\"Type de fichier non support√© pour {url_dataset}\")\n",
    "    \n",
    "    if options==\"\": \n",
    "        options = \"\" \n",
    "    if 'csv' in url_dataset and safe_mode==True: \n",
    "        options = \", all_varchar=1\" \n",
    "    if nom_table==\"\": \n",
    "        nom_table = \"loaded_dataset\"\n",
    "    \n",
    "    try:\n",
    "        status = ddb.sql(f\"\"\"\n",
    "            create or replace table {nom_table} as select *\n",
    "            from\n",
    "            {loader}(\"{url_dataset}\" {options})\n",
    "        \"\"\")\n",
    "        return status\n",
    "    except Exception as e:\n",
    "        return f\"Erreur au chargement du fichier : {str(e)}\"\n",
    "\n",
    "def run_query(sql):\n",
    "    return ddb.sql(sql.replace(\"`\",\" \")).to_df()\n",
    "\n",
    "# Chargement des donn√©es\n",
    "load_file_from_url_lite(\"https://object.files.data.gouv.fr/meteofrance/data/synchro_ftp/BASE/QUOT/Q_64_previous-1950-2023_RR-T-Vent.csv.gz\", safe_mode=True)\n",
    "print(\"‚úÖ Donn√©es charg√©es avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Analyse SQL\n",
    "\n",
    "Cette requ√™te utilise des techniques SQL pour extraire et transformer les donn√©es de mani√®re efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T09:59:46.830323Z",
     "iopub.status.busy": "2025-08-21T09:59:46.830323Z",
     "iopub.status.idle": "2025-08-21T09:59:46.941617Z",
     "shell.execute_reply": "2025-08-21T09:59:46.941617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©sultats : 74 lignes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annee</th>\n",
       "      <th>integral_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>1354.693791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951</td>\n",
       "      <td>1537.841796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952</td>\n",
       "      <td>1583.263803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953</td>\n",
       "      <td>915.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954</td>\n",
       "      <td>1498.891898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annee  integral_precipitation\n",
       "0   1950             1354.693791\n",
       "1   1951             1537.841796\n",
       "2   1952             1583.263803\n",
       "3   1953              915.175000\n",
       "4   1954             1498.891898"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ex√©cution de la requ√™te\n",
    "df = run_query(\"\"\" WITH daily_avg_rr AS (\n",
    "  SELECT \n",
    "    CAST(SUBSTRING(\"AAAAMMJJ\", 1, 4) AS INTEGER) AS annee,\n",
    "    CAST(SUBSTRING(\"AAAAMMJJ\", 5, 2) AS INTEGER) AS mois,\n",
    "    CAST(SUBSTRING(\"AAAAMMJJ\", 7, 2) AS INTEGER) AS jour,\n",
    "    AVG(CAST(\"RR\" AS DOUBLE)) AS avg_rr\n",
    "  FROM loaded_dataset\n",
    "  GROUP BY \"AAAAMMJJ\"\n",
    "),\n",
    "cumulative_sum AS (\n",
    "  SELECT \n",
    "    annee,\n",
    "    jour,\n",
    "    mois,\n",
    "    SUM(avg_rr) OVER (PARTITION BY annee ORDER BY mois, jour) AS cum_sum_rr\n",
    "  FROM daily_avg_rr\n",
    ")\n",
    "SELECT \n",
    "  annee, \n",
    "  cum_sum_rr AS integral_precipitation\n",
    "FROM cumulative_sum\n",
    "WHERE mois = 12 AND jour = 31\n",
    "ORDER BY annee \"\"\")\n",
    "print(f\"R√©sultats : {len(df)} lignes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualisation\n",
    "\n",
    "La biblioth√®que principale utilis√©e est Matplotlib, qui est une des biblioth√®ques de visualisation de donn√©es les plus populaires en Python. Elle est adapt√©e pour cr√©er des graphiques de haute qualit√© avec une grande flexibilit√© dans la personnalisation, ce qui est id√©al pour repr√©senter des donn√©es temporelles comme les pr√©cipitations annuelles cumul√©es. Matplotlib permet une visualisation claire et d√©taill√©e des donn√©es, avec des options de mise en forme avanc√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T09:59:46.957120Z",
     "iopub.status.busy": "2025-08-21T09:59:46.941617Z",
     "iopub.status.idle": "2025-08-21T09:59:48.083915Z",
     "shell.execute_reply": "2025-08-21T09:59:48.082804Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m savgol_filter\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      8\u001b[0m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.family\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource Sans Pro\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb as ddb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Source Sans Pro'\n",
    "mpl.rcParams['font.size'] = 10\n",
    "\n",
    "# Mise en ordre\n",
    "df = df.sort_values('annee').reset_index(drop=True)\n",
    "\n",
    "# Calcul du lissage 20 ans\n",
    "window = min(20, len(df) - (len(df) % 2 == 0))\n",
    "polyorder = min(3, window - 1)\n",
    "df['precip_lisse'] = savgol_filter(df['integral_precipitation'], window_length=window, polyorder=polyorder)\n",
    "\n",
    "# Pr√©paration figure\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Courbes\n",
    "ax.plot(df['annee'], df['integral_precipitation'], \n",
    "        color='#ff6666', linewidth=1.2, label='Donn√©es brutes', alpha=0.8)\n",
    "ax.plot(df['annee'], df['precip_lisse'], \n",
    "        color='#1f77b4', linewidth=2.5, label='Courbe liss√©e 20 ans')\n",
    "\n",
    "# Points min/max\n",
    "min_idx = df['integral_precipitation'].idxmin()\n",
    "max_idx = df['integral_precipitation'].idxmax()\n",
    "for idx, color in [(min_idx, 'red'), (max_idx, 'red')]:\n",
    "    ax.scatter(df.at[idx, 'annee'], df.at[idx, 'integral_precipitation'], \n",
    "               color=color, s=60, zorder=5, edgecolors='white', linewidth=1.5)\n",
    "    ax.annotate(f\"{df.at[idx, 'integral_precipitation']:.0f}\", \n",
    "                xy=(df.at[idx, 'annee'], df.at[idx, 'integral_precipitation']),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', edgecolor=color, alpha=0.7),\n",
    "                fontweight='bold', clip_on=True)\n",
    "\n",
    "# Mise en forme\n",
    "ax.set_title('Pr√©cipitations annuelles cumul√©es liss√©es sur 20 ans', pad=20, fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Ann√©es (1950-2023)', labelpad=10)\n",
    "ax.set_ylabel('Pr√©cipitations cumul√©es (mm)', labelpad=10)\n",
    "ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n",
    "ax.set_xlim(df['annee'].min() - 1, df['annee'].max() + 1)\n",
    "legend = ax.legend(loc='upper left', frameon=True, fancybox=True, shadow=True)\n",
    "legend.get_frame().set_facecolor('white')\n",
    "legend.get_frame().set_edgecolor('lightgray')\n",
    "plt.tight_layout()\n",
    "\n",
    "dataviz = fig\n",
    "dataviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Made with ‚ù§Ô∏è and with [duckit.fr](https://duckit.fr) - [Ali Hmaou](https://www.linkedin.com/in/ali-hmaou-6b7b73146/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T09:59:48.083915Z",
     "iopub.status.busy": "2025-08-21T09:59:48.083915Z",
     "iopub.status.idle": "2025-08-21T09:59:48.695038Z",
     "shell.execute_reply": "2025-08-21T09:59:48.694038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVERTISSEMENT: Aucune variable 'dataviz' trouv√©e.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Variables inject√©es par le script ---\n",
    "FINAL_OBJECT_VARIABLE_NAME = 'dataviz'\n",
    "OUTPUT_IMAGE_NAME = 'published\\\\notebooks\\\\duckit_analysis_20250820_222740.png'\n",
    "OUTPUT_HTML_NAME = 'published\\\\notebooks\\\\duckit_analysis_20250820_222740.html'\n",
    "\n",
    "# ===================================================================\n",
    "# CELLULE INJECT√âE AUTOMATIQUEMENT (VERSION ROBUSTE)\n",
    "# ===================================================================\n",
    "import sys\n",
    "import os\n",
    "# On importe les modules n√©cessaires pour l'export au cas o√π\n",
    "try:\n",
    "    from bokeh.io import save as bokeh_save\n",
    "except ImportError:\n",
    "    bokeh_save = None\n",
    "\n",
    "try:\n",
    "    # On s'assure que le dossier de sortie existe\n",
    "    output_dir = os.path.dirname(OUTPUT_IMAGE_NAME)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # On utilise globals().get() pour une r√©cup√©ration plus s√ªre\n",
    "    final_object = globals().get(FINAL_OBJECT_VARIABLE_NAME)\n",
    "\n",
    "    if final_object is None:\n",
    "        # On l√®ve une NameError pour √™tre coh√©rent avec le code original\n",
    "        raise NameError(f\"name '{FINAL_OBJECT_VARIABLE_NAME}' is not defined\")\n",
    "\n",
    "    print(f\"INFO: Variable '{FINAL_OBJECT_VARIABLE_NAME}' trouv√©e. Tentative d'exportation...\")\n",
    "\n",
    "    object_type = str(type(final_object))\n",
    "\n",
    "    if 'plotly.graph_objs._figure.Figure' in object_type:\n",
    "        print(f\"--> D√©tect√© : Plotly. Sauvegarde HTML et PNG.\")\n",
    "        # 1. Sauvegarde HTML pour l'interactivit√©\n",
    "        print(f\"--> Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.write_html(OUTPUT_HTML_NAME, include_plotlyjs='cdn')\n",
    "        # 2. Sauvegarde PNG pour l'aper√ßu statique\n",
    "        try:\n",
    "            print(f\"--> Tentative de sauvegarde PNG directe dans : {OUTPUT_IMAGE_NAME}\")\n",
    "            final_object.write_image(OUTPUT_IMAGE_NAME, scale=3, width=1200, height=800)\n",
    "            print(f\"--> Image Plotly sauvegard√©e avec succ√®s.\")\n",
    "        except Exception as e:\n",
    "            print(f\"AVERTISSEMENT: La sauvegarde directe en PNG a √©chou√© (kaleido est-il install√©?).\", file=sys.stderr)\n",
    "            print(f\"   Erreur: {e}\", file=sys.stderr)\n",
    "            print(f\"--> PLAN B: On va utiliser la capture d'√©cran du HTML √† la place.\")\n",
    "            # On cr√©e un fichier marqueur pour que le script de post-traitement prenne le relais\n",
    "            with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "                f.write(\"plotly\")\n",
    "    elif 'folium.folium.Map' in object_type:\n",
    "        print(f\"--> D√©tect√© : Folium. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.save(OUTPUT_HTML_NAME)\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"folium\")\n",
    "    elif 'altair.vegalite' in object_type and hasattr(final_object, 'save'):\n",
    "        print(f\"--> D√©tect√© : Altair. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        final_object.save(OUTPUT_HTML_NAME)\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"altair\")\n",
    "    elif 'bokeh.plotting' in object_type and bokeh_save is not None:\n",
    "        print(f\"--> D√©tect√© : Bokeh. Sauvegarde HTML dans : {OUTPUT_HTML_NAME}\")\n",
    "        bokeh_save(final_object, filename=OUTPUT_HTML_NAME, title=\"\")\n",
    "        # On cr√©e un fichier marqueur g√©n√©rique pour la capture d'√©cran\n",
    "        print(f\"--> Cr√©ation du marqueur de capture d'√©cran.\")\n",
    "        with open(f\"{OUTPUT_HTML_NAME}.needs_screenshot\", \"w\") as f:\n",
    "            f.write(\"bokeh\")\n",
    "    elif 'matplotlib.figure.Figure' in object_type:\n",
    "        print(f\"--> D√©tect√© : Matplotlib. Sauvegarde dans : {OUTPUT_IMAGE_NAME}\")\n",
    "        final_object.savefig(OUTPUT_IMAGE_NAME, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        print(f\"AVERTISSEMENT: Type non support√© : {object_type}\", file=sys.stderr)\n",
    "except NameError:\n",
    "    print(f\"AVERTISSEMENT: Aucune variable '{FINAL_OBJECT_VARIABLE_NAME}' trouv√©e.\", file=sys.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"ERREUR lors de l'exportation : {e}\", file=sys.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "3ab1ff277d8940059b2a34313cdba807": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": "black",
       "description_width": ""
      }
     },
     "4a247f56a5af4de88916dcb9bcfbbcb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "auto"
      }
     },
     "d51557c126f94822a425dbe9e4365dd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4a247f56a5af4de88916dcb9bcfbbcb6",
       "max": 100.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3ab1ff277d8940059b2a34313cdba807",
       "tabbable": null,
       "tooltip": null,
       "value": 100.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
